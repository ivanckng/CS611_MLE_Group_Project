The data source is stored at Google Cloud Storage. To run the notebooks, we should read the data from cloud first.
Cloud Service: Google Cloud Platform
Google Group: CS611_MLE_Group_9 (if you have not joined the group, please contact Junqi)

PLEASE FOLLOW THE STEPS BEFORE DOING ANYTHING!!!!!!!!!


##### IF RUNNING IN YOUR LOCAL MACHINE, PLEASE FOLLOW THE FOLLOWING STEPS #####
1. Install Google Cloud CLI
    https://cloud.google.com/sdk/docs/install
2. Run the following code in local terminal to get authentication 
    gcloud auth application-default login
3. Upon Authentication by GCP, you will be assigned a credentials whose paths will be displayed in terminal, copy it.
4. Back to IDE and start a new terminal, create a new docker image, by running:
    docker build -t <your_customised_image_name> . 
5. To run the image, by running:
    docker run -it --rm -p 8890:8890 -v "<your_credential_path>:/app/.config/gcloud:ro" -e GOOGLE_APPLICATION_CREDENTIALS="/app/.config/gcloud/application_default_credentials.json" <your_customised_image_name> jupyter lab --ip=0.0.0.0 --port=8890 --no-browser --allow-root --NotebookApp.token=''
6. Now you can click the URL and launch the Jupyter notebook and do ETL from Google Cloud Storage